{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCVでとことん画像処理 - 前半\n",
    "\n",
    "このノートは **前半** のノートになります。前半では\n",
    "\n",
    "+ [画像を扱う際の簡単な基礎知識](#basic)\n",
    "    + [画像処理のよく使われる場面など](#example)\n",
    "    + [表色系と色空間](#color)\n",
    "+ [画素ごとの濃淡変換](#contrast)\n",
    "    + [トーンカーブ](#tonecurve)\n",
    "    + [LUTによる高速濃淡変換](#LUT)\n",
    "    + [(おまけ)salt\\_pepperノイズ](#sp_noise)\n",
    "+ [複数画像の利用](#multi_img)\n",
    "    + [アルファブレンディング](#alpha)\n",
    "    + [ディゾルブ](#dissolve)\n",
    "    \n",
    "を扱います。\n",
    "\n",
    "※追記: Python 3.8.2, chromiumベースブラウザ で動作を確認しております"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# これを書くとjupyterでmatplotlibなどが出力する画像の解像度が上がる\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "\n",
    "from utils.plot import compare_plot\n",
    "\n",
    "print(cv2.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basic\"></a>\n",
    "## 画像を扱う際の簡単な知識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デジタル画像は、多数の画素で構成されていて、画素値を多数の数値データと考えることでデータの前処理を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは画像を読み込んでみましょう\n",
    "img = cv2.imread(\"../../data/Lenna.png\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlibで画像を出力する場合はimshowを使用\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上記なままではBGRの順番で読み込む(色空間については後述)のでRGBへ変換します\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上のRGB画像をグレー画像にして読み込みます\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値データで見てみます。カラーなので[red,green,blue]の色が0~255で格納されています。\n",
    "img[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"example\"></a>\n",
    "### 画像処理のよく使われる場面など\n",
    "\n",
    "カラーの画像分類チュートリアルによく使用されるCIFAR-10データセットなども、上記のように数値で表現された画像から特徴を学習させていきます。\n",
    "<img src=\"../fig/cifar10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"color\"></a>\n",
    "## 表色系と色空間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色を心理的な観点から**色相(Hue)**、**明度(Saturation)**、**彩度(Value)**の三属性で表す方法をマンセル表色系と呼びます。\n",
    "\n",
    "+ 色相\n",
    "    + 色の違いを示す属性\n",
    "+ 明度\n",
    "    + 各色相の明るさを表す属性\n",
    "+ 彩度\n",
    "    + 彩度は色の鮮やかさを示す属性\n",
    "    \n",
    "<img src=\"../fig/muncell_colormap.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一つの円の円周上で5等分するように配置します。色はR(赤), Y(黄), G(緑), B(青), P(紫)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB表色\n",
    "\n",
    "CIE（国際照明委員会）が定める表色系。RGB表色系原色をR（赤、700nm）、G（緑、546.1nm）、B（青、435.8nm）とする表色系を、CIEのRGB表色系と呼んでいます。  \n",
    "\n",
    "これらRGB表色系をベースとして画像処理を行っていきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contrast\"></a>\n",
    "## 画素ごとの濃淡変換\n",
    "濃淡の変換は単純な処理ではありますが、画像の「**見栄え**」を変えたりするためなどに、使用される画像処理になります。  \n",
    "\n",
    "酒直関数の画素値に対して、どうやって対応づけるかを指定することを階調変換といい、それをグラフで表したものを**トーンカーブ**と呼びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ヒストグラム\n",
    "画像のコントラストを上げたい時、まずは画像のヒストグラムを調べて分布を見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,0] #R(赤)の画素値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"RED\", \"GREEN\", \"BLUE\"]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18,6))\n",
    "for i, rgb in enumerate(labels):\n",
    "    img_rgb = img[:,:,i]\n",
    "    ax[i].hist(img_rgb.ravel(),256,[0,256]);\n",
    "    ax[i].set_title(\"img_{}\".format(rgb))\n",
    "    ax[i].set_xlabel(\"image pixel value\")\n",
    "    ax[i].set_ylabel(\"number of value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ヒストグラム平坦化\n",
    "偏りが集中している場合はその画素をできるだけ広げて均等に分布することで、明るさの違う画像でもトーンカーブの結果を等しくすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集中していた山がなだらかになります\n",
    "labels = [\"RED\", \"GREEN\", \"BLUE\"]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18,6))\n",
    "img_rgb = []\n",
    "for i, rgb in enumerate(labels):\n",
    "    # ヒストグラムを平坦化する\n",
    "    equ = cv2.equalizeHist(img[:,:,i])\n",
    "    \n",
    "    img_rgb.append(equ)\n",
    "    ax[i].hist(equ.ravel(),256,[0,256]);\n",
    "    ax[i].set_title(\"img_{}\".format(rgb))\n",
    "    ax[i].set_xlabel(\"image pixel value\")\n",
    "    ax[i].set_ylabel(\"number of value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hist = np.dstack((np.dstack((img_rgb[0], img_rgb[1])), img_rgb[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元画像とヒストグラム平坦化後の比較\n",
    "compare_plot([img, img_hist], [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"../../data/Lenna_flat.png\", cv2.cvtColor(img_hist, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tonecurve\"></a>\n",
    "## トーンカーブ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 折れ線型トーンカーブ\n",
    "折れ線で表されるトーンカーブでは、カーブの設計が容易であるため実際によく用いられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyline = np.vectorize(lambda x: 0 if x < 64 else 2*(x-64) if (64 <= x <192) else 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([polyline(i) for i in range(256)])\n",
    "plt.xlabel(\"input pixel\")\n",
    "plt.ylabel(\"output pixel\")\n",
    "plt.title(\"polyline graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, polyline(img_hist).astype(\"uint8\")], \\\n",
    "        [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S字トーンカーブ\n",
    "画素値の127を境として、低い入力値(暗部)はより低い出力値に、高い入力値(明部)はより高い出力値に変換されるので、結果として暗部・明部が強調され、出力画像を見るとコントラストが高くなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_shape_curve = np.vectorize(lambda x: (np.sin(np.pi * (x/255 - 0.5)) + 1)/2 * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([s_shape_curve(i) for i in range(256)])\n",
    "plt.xlabel(\"input pixel\")\n",
    "plt.ylabel(\"output pixel\")\n",
    "plt.title(\"S shape curve graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, s_shape_curve(img_hist).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ガンマ変換\n",
    "\n",
    "ガンマ変換（ガンマ補正）とは下記の関数に則って画素値を変換する手法になっています。\n",
    "\n",
    "$$ y = 255 \\cdot (\\frac{x}{255})^{\\frac{1}{\\gamma}} $$\n",
    "\n",
    "画素値を明るくしたい場合にはガンマの値を1より大きくすることで明るくすることができ、逆に暗くしたい場合にはガンマの値を1より小さくすることで暗くすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_gamma(x, gamma):\n",
    "    return 255 * (x/255) ** (1/gamma)\n",
    "\n",
    "g_curve_light = np.vectorize(lambda x: curve_gamma(x, 2))\n",
    "g_curve_dark= np.vectorize(lambda x: curve_gamma(x, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"gamma curve (gamma=2)\", \"gamma curve (gamma=0.5)\"]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18,6))\n",
    "for i, graph in enumerate([[g_curve_light(i) for i in range(256)], [g_curve_dark(i) for i in range(256)]]):\n",
    "    ax[i].plot(graph)\n",
    "    ax[i].set_title(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を明るくするガンマ変換\n",
    "compare_plot([img_hist, g_curve_light(img_hist).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を暗くするガンマ変換\n",
    "compare_plot([img_hist, g_curve_dark(img_hist).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LUT\"></a>\n",
    "## LUT(Look Up Table)による高速濃淡変換\n",
    "ルックアップテーブルとは複雑な画像処理を単純なリストや配列の参照処理で置き換えて効率化を図るために作られたもので、これによって画像処理を高速化することができます。\n",
    "\n",
    "例えば、フルHD(1920×1080)であれば2073600個の画素があります。フルHDの画像の階調変換を一回行おうとすると、素朴に考えて変換の計算を2073600回行わねばならないことになります。RGB各チャンネルに変換処理を行うとその3倍となります。\n",
    "\n",
    "しかしよく考えると、入力も出力も、取りうる値は 0から255 の整数となります。画素値変換の対応は 256 通りなので、変換の計算を行わずに、「0から255 の各入力値に対して、出力値が 0から255 のうちどれに対応するか」 を示す表をあらかじめ作っておいて、変換時は画素値の計算をすることで高速に処理ができます。表の作成自体は256回の計算で済むので、単調に計算処理をするより早くなるというメカニズムです。\n",
    "\n",
    "### ネガポジ反転"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_pos_rev_LUT(img):\n",
    "    look_up_table = np.zeros((256, 1), dtype = 'uint8') \n",
    "    for i in range(256):\n",
    "        look_up_table[i][0] = 255 - i\n",
    "    img_np_rev_LUT = cv2.LUT(img, look_up_table)\n",
    "    return img_np_rev_LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, neg_pos_rev_LUT(img_hist)], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 速度比較\n",
    "実際にLUTと通常の画素値変換の速度を比較してみようと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_rev = np.vectorize(lambda x: x * (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([neg_pos_rev(i) for i in range(256)])\n",
    "plt.xlabel(\"input pixel\")\n",
    "plt.ylabel(\"output pixel\")\n",
    "plt.title(\"negative positive reverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, neg_pos_rev(img_hist).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通常の画素値変換を計測\n",
    "tic = time.time()\n",
    "neg_pos_rev(img_hist)\n",
    "toc = time.time()\n",
    "print(\"Execution Time: {} sec\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUTを使ったテーブル変換を計測\n",
    "tic = time.time()\n",
    "neg_pos_rev_LUT(img_hist)\n",
    "toc = time.time()\n",
    "print(\"Execution Time: {} sec\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LUTを使った速度のほうが約80倍近く高速化できていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ポスタリゼーション(n値化)\n",
    "画素値を数段階に制限して出力するような変換をポスタリゼーションと呼んでおり、さらに出力値を2段階に制限している処理は特に2値化(バイナリゼーション)と呼んでいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterize_LUT(img, n):\n",
    "    look_up_table = np.zeros((256, 1), dtype = 'uint8') \n",
    "    for i in range(256):\n",
    "        look_up_table[i][0] = np.floor(i/(256/n+1)) * 256/(n)\n",
    "    img_np_rev_LUT = cv2.LUT(img, look_up_table)\n",
    "    return img_np_rev_LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterize = lambda x, n: np.floor(x/(256/n+1)) * 256/(n)\n",
    "plt.plot([posterize(i,256) for i in range(256)])\n",
    "plt.xlabel(\"input pixel\")\n",
    "plt.ylabel(\"output pixel\")\n",
    "plt.title(\"posterization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階調を4段階に(2の2乗)して変換\n",
    "compare_plot([img_hist, posterize_LUT(img_hist, 3).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポスタリゼーションは特にグレー画像にていい感じに効果を発揮することが多いですが、上記のようなRGB画像のような画像では段階を複雑にするほど色の組み合わせが増えるため、うまくいかないことが多い傾向にあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グレー画像を2値化\n",
    "compare_plot([img_gray, posterize_LUT(img_gray, 6).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"],\n",
    "            [\"gray\", \"gray\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sp_noise\"></a>\n",
    "## (おまけ)ソルト・ペッパーノイズ\n",
    "塩と胡椒をかけたようなノイズなので一般的にはこう呼ばれており、インパルスノイズとも呼ばれるものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_noize(img, sp, amount):\n",
    "    row,col,ch = img.shape\n",
    "    s_vs_p = sp # 塩と胡椒の割合\n",
    "    amount = amount # 画像の何割をノイズ化するか\n",
    "    sp_img = img.copy()\n",
    "\n",
    "    # salt\n",
    "    num_salt = np.ceil(amount * img.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i-1 , int(num_salt)) for i in img.shape]\n",
    "    sp_img[coords[:-1]] = (255,255,255)\n",
    "\n",
    "    # pepper\n",
    "    num_pepper = np.ceil(amount* img.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i-1 , int(num_pepper)) for i in img.shape]\n",
    "    sp_img[coords[:-1]] = (0,0,0)\n",
    "    \n",
    "    return sp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, sp_noize(img_hist, 0.5, 0.005).astype(\"uint8\")], \\\n",
    "            [\"before\", \"after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multi_img\"></a>\n",
    "## 複数画像の利用\n",
    "これまでの画像処理は1枚の画像に対する処理でしたが、複数枚用いるような画像処理についても紹介していきたいと思います。複数画像用にもう1枚画像を読み込んでいきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat = cv2.cvtColor(cv2.imread(\"../../data/kuroneko.png\"), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"alpha\"></a>\n",
    "## アルファブレンディング\n",
    "アルファブレンディングとは2枚の画像を重みを基準にして合成したような画像を作成する処理のことを指しています。具体的に式にしてみると以下のように表せます。\n",
    "\n",
    "$$ g = \\alpha \\cdot f_1 + (1 - \\alpha) \\cdot f_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_blend(img1, img2, alpha):\n",
    "    return cv2.addWeighted(img1, alpha, img2,(1-alpha), 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot([img_hist, img_cat, alpha_blend(img_hist, img_cat, 0.5)], \\\n",
    "            [\"img1\", \"img2\", \"alpha_blending\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dissolve\"></a>\n",
    "## ディゾルブ\n",
    "アルファブレンディングを応用した例の一つにディゾルブという手法があり、アルファを時間的に変化させることで、あるシーンから別のシーンに徐々に変換していくような処理をすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディゾルブ(時間ごとにαが変化して画像が切り替わります)\n",
    "if os.path.isfile('../../data/dissolve.mp4'):\n",
    "    os.remove('../../data/dissolve.mp4')\n",
    "\n",
    "# videoの縦横サイズは画像と一致しないとうまく書き出せないので注意\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "video = cv2.VideoWriter('../../data/dissolve.mp4', fourcc, 30.0, (512, 512))\n",
    "\n",
    "for ratio in range(1, 101):\n",
    "    img_alpha_blend = alpha_blend(img_hist, img_cat, ratio*0.01)\n",
    "    video.write(cv2.cvtColor(img_alpha_blend, cv2.COLOR_RGB2BGR))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"../../data/dissolve.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献・サイト\n",
    "\n",
    "+ ディジタル画像処理 改訂新版 2~4章\n",
    "+ トーンカーブ と LUT を理解する実装実験\n",
    "> http://optie.hatenablog.com/entry/2018/03/03/141427"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
